{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e33f95bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import Comment\n",
    "#import re\n",
    "#import html5lib\n",
    "from lxml import html\n",
    "from bs4 import  BeautifulSoup\n",
    "#from time import sleep\n",
    "#from selenium import webdriver\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#exploring this for later, using selenium/webdriver may make scraping certain pages significantly easier\n",
    "#tho it feels kinda illegal idk\n",
    "# def parse(url):\n",
    "#     response = webdriver.Chrome()\n",
    "#     response.get(url)\n",
    "#     sleep(3)\n",
    "#     sourceCode=response.page_source\n",
    "#     return  sourceCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90264e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#basic structure to how this program will work, this was exploratory\n",
    "# url = \"https://www.pro-football-reference.com/years/2022/opp.htm\"\n",
    "\n",
    "# data = requests.get(url)\n",
    "# soup = BeautifulSoup(data.text)\n",
    "\n",
    "# advdef = pd.read_html(data.text, match = \"Team Advanced Defense Table\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67442aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a492f0af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73ee9c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The ddvanced defence table is really good data, but only exists for 2018 onwards sadge\n",
    "years = list(range(2022,2017,-1))\n",
    "\n",
    "\n",
    "# AdvancedDefTabl = advdef.insert(0,\"Year\",2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70d695da",
   "metadata": {},
   "outputs": [],
   "source": [
    "AdvancedDefTabl = pd.DataFrame()\n",
    "for year in years:\n",
    "    url1 = \"https://www.pro-football-reference.com/years/\" + str(year) + \"/opp.htm\"\n",
    "    data = requests.get(url1)\n",
    "    soup = BeautifulSoup(data.text)\n",
    "    advdef1 = pd.read_html(data.text, match = \"Team Advanced Defense Table\")[0]\n",
    "    advdef1.insert(0, \"Year\", year)\n",
    "    AdvancedDefTabl = pd.concat([AdvancedDefTabl,advdef1])\n",
    "# AdvancedDefTabl.tail()\n",
    "\n",
    "#loop to grap all the data for the advanced defense table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb724d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdvancedDefTabl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f8e437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Loop\n",
    "Times = list(range(2021,2009,-1))\n",
    "# AdvancedDefTabl = pd.DataFrame()\n",
    "Teamdeftable = pd.DataFrame()\n",
    "passdeftable = pd.DataFrame()\n",
    "rushdeftable = pd.DataFrame()\n",
    "returnsagainsttable= pd.DataFrame()\n",
    "kicksagainsttable= pd.DataFrame()\n",
    "scoringdeftable= pd.DataFrame()\n",
    "convtable= pd.DataFrame()\n",
    "driveavgtable= pd.DataFrame()\n",
    "\n",
    "for Time in Times:\n",
    "    \n",
    "    url1 = \"http://www.pro-football-reference.com/years/\" + str(Time) + \"/opp.htm#all_advanced\"\n",
    "    data = requests.get(url1)\n",
    "    \n",
    "    soup = BeautifulSoup(data.text)\n",
    "#     soup = re.sub(r'<.*?>', lambda g: g.group(0).upper(), soup.text)\n",
    "    teamdef = pd.read_html(data.text, match = \"Team Defense Table\")[0]\n",
    "    teamdef.insert(0, \"Time\", Time)\n",
    "    Teamdeftable = pd.concat([Teamdeftable,teamdef])\n",
    "    \n",
    "    \n",
    "    #This is where the fun begins, Not sure why, but the data for the rest of the tables on the page do not load in correctly \\\n",
    "    #with the request method, and the tables are converted into comment objects, luckily bsoup can parse through the comments\n",
    "    #and get the tables anyway, which I load into \"tables\". I then loop through and simply assign these tables to pd dataframes\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "    tables = []\n",
    "    for i in comments:\n",
    "        if 'table' in i:\n",
    "            try:\n",
    "                tables.append(pd.read_html(i)[0])\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    passdef = tables[0]\n",
    "    passdef.insert(0, \"Time\", Time)\n",
    "    passdeftable = pd.concat([passdeftable,passdef])\n",
    "    \n",
    "    rushdef = tables[1]\n",
    "    rushdef.insert(0, \"Time\", Time)\n",
    "    rushdeftable = pd.concat([rushdeftable,rushdef])\n",
    "    \n",
    "    returnsagainst = tables[2]\n",
    "    returnsagainst = returnsagainst.iloc[0: , :]\n",
    "    returnsagainst.insert(0, \"Time\", Time)\n",
    "    returnsagainsttable = pd.concat([returnsagainsttable,returnsagainst])\n",
    "    \n",
    "    kicksagainst = tables[3]\n",
    "    kicksagainst = kicksagainst.iloc[0: , :]\n",
    "    kicksagainst.insert(0, \"Time\", Time)\n",
    "    kicksagainsttable = pd.concat([kicksagainsttable,kicksagainst])\n",
    "    \n",
    "    scoringdef = tables[4]\n",
    "    scoringdef.insert(0, \"Time\", Time)\n",
    "    scoringdeftable = pd.concat([scoringdeftable,scoringdef])\n",
    "    \n",
    "    conv = tables[5]\n",
    "    conv = conv.iloc[0: , :]\n",
    "    conv.insert(0, \"Time\", Time)\n",
    "    convtable = pd.concat([convtable,conv])\n",
    "    \n",
    "    driveavg = tables[6]\n",
    "    driveavg = driveavg.iloc[0: , :]\n",
    "    driveavg.insert(0, \"Time\", Time)\n",
    "    driveavgtable = pd.concat([driveavgtable,driveavg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb89de41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "writer = pd.ExcelWriter('Massive Cock File.xlsx',engine='xlsxwriter')   \n",
    "\n",
    "AdvancedDefTabl.to_excel(writer,sheet_name='Advanced Defense',startrow=0 , startcol=0)\n",
    "Teamdeftable.to_excel(writer,sheet_name='Team Defense',startrow=0 , startcol=0)\n",
    "passdeftable.to_excel(writer,sheet_name='Passing Defense',startrow=0 , startcol=0)\n",
    "rushdeftable.to_excel(writer,sheet_name='Rushing Defense',startrow=0 , startcol=0)\n",
    "returnsagainsttable.to_excel(writer,sheet_name='Returns Against',startrow=0 , startcol=0)\n",
    "kicksagainsttable.to_excel(writer,sheet_name='Kicking Punt Against',startrow=0 , startcol=0)\n",
    "scoringdeftable.to_excel(writer,sheet_name='Scoring Defense',startrow=0 , startcol=0)\n",
    "convtable.to_excel(writer,sheet_name='Conversions Against',startrow=0 , startcol=0)\n",
    "driveavgtable.to_excel(writer,sheet_name='Drive Averages',startrow=0 , startcol=0)\n",
    "writer.save()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d598f206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6da650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8618f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_html(str(soup.find_all('table')[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2bac86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05e50bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tables = soup.find_all('table')\n",
    "# print(len(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d057f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed345894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "\n",
    "# tables = []\n",
    "# for each in comments:\n",
    "#     if 'table' in each:\n",
    "#         try:\n",
    "#             tables.append(pd.read_html(each)[0])\n",
    "#         except:\n",
    "#             continue\n",
    "# tables[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e062ff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b3bac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_list = []\n",
    "# for t in soup.find_all(\"table\"):\n",
    "#     if t.get(\"class\"):\n",
    "#         my_list.append(t[\"class\"])\n",
    "# my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f243079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "\n",
    "# tables = []\n",
    "# for each in comments:\n",
    "#     if 'table' in each:\n",
    "#         try:\n",
    "#             tables.append(pd.read_html(each)[0])\n",
    "#         except:\n",
    "#             continue\n",
    "# len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9510c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebe48de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1251a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
